{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c22f3aed-5dda-45f5-89bb-3dde0169c3a4",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a3fee7-ee76-42fe-9c18-82dd9b528c06",
   "metadata": {},
   "source": [
    "##### The model is built using keras.Sequential() with multiple dense layers and dropout regularization to prevent overfitting. The output layer uses a linear activation function for regression. The model is compiled with the Adam optimizer (learning rate of 0.001), MSE as the loss function, and RMSE as the evaluation metric. For callbacks, EarlyStopping halts training if the validation loss doesn't improve for 28 epochs, while ReduceLROnPlateau reduces the learning rate by 0.1 if the validation loss stagnates for 24 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29e368e-a69c-49a1-851f-c4ff0cf784a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load processed train data\n",
    "train_data = pd.read_csv('../data/processed/train_data_processed.csv').copy()\n",
    "\n",
    "# Select features and target variable\n",
    "selected_features = [\n",
    "    \"milage\", \"age\", \"hp\", \"engine_size\", \n",
    "    \"cylinders\", \"speed\", \"has_auto_shift\", \"accident_mapped\",\n",
    "    \"int_col_mapped\", \"ext_col_mapped\", \"luxury_category\"\n",
    "]\n",
    "\n",
    "X = train_data[selected_features]  # Features\n",
    "y = train_data['price']  # Target\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build the deep learning model with multiple dense layers and dropout regularization\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(250, activation='relu', kernel_regularizer=keras.regularizers.l2(0.02)),  \n",
    "    layers.Dropout(0.4),  \n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),  \n",
    "    layers.Dropout(0.3),  \n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),  \n",
    "    layers.Dropout(0.2),  \n",
    "    layers.Dense(32, activation='relu', kernel_regularizer=keras.regularizers.l2(0.005)),  \n",
    "    layers.Dropout(0.1),  \n",
    "    layers.Dense(16, activation='relu'),  \n",
    "    layers.Dense(1, activation='linear')  # Output layer with linear activation for regression\n",
    "])\n",
    "\n",
    "# Compile the model with Adam optimizer, MSE loss, and RMSE metric\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),  # Adam optimizer with a learning rate of 0.001\n",
    "    loss='mean_squared_error',  # Loss function: Mean Squared Error (MSE)\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"root_mean_squared_error\")]  # RMSE metric\n",
    ")\n",
    "\n",
    "# Set up EarlyStopping and ReduceLROnPlateau callbacks to prevent overfitting\n",
    "es = EarlyStopping(monitor='val_loss', patience=28, restore_best_weights=True)\n",
    "lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=24, min_lr=1e-6)\n",
    "\n",
    "# Train the model with the training data and validation data\n",
    "history = model.fit(X_train_scaled, y_train, \n",
    "                    validation_data=(X_test_scaled, y_test),\n",
    "                    epochs=100, batch_size=32, verbose=1,\n",
    "                    callbacks=[es, lr])  # Early stopping and learning rate reduction\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_rmse = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"\\nTest RMSE: {test_rmse:.2f}\")\n",
    "\n",
    "# Save the trained model to disk\n",
    "model.save(\"../models/car_price_prediction_model.h5\")\n",
    "print(\"Model successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
